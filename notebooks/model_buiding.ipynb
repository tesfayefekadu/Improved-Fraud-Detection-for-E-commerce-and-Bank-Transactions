{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from model_building_and_training import (\n",
    "    separate_features_target_creditcard,\n",
    "    separate_features_target_fraud,\n",
    "    split_train_test,\n",
    "    train_and_evaluate_model,get_column_types\n",
    ")\n",
    "from data_analysis_and_preprocessing import correct_data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "creditcard_df = pd.read_csv('../data/creditcard.csv')\n",
    "merged_fraud_df = pd.read_csv('../data/merged_fraud_data.csv')\n",
    "\n",
    "# Correct data types for fraud data\n",
    "merged_fraud_df1 = correct_data_types(merged_fraud_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>signup_time</th>\n",
       "      <th>purchase_time</th>\n",
       "      <th>purchase_value</th>\n",
       "      <th>device_id</th>\n",
       "      <th>source</th>\n",
       "      <th>browser</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>ip_address</th>\n",
       "      <th>class</th>\n",
       "      <th>lower_bound_ip_address</th>\n",
       "      <th>upper_bound_ip_address</th>\n",
       "      <th>country</th>\n",
       "      <th>time_to_purchase</th>\n",
       "      <th>hour_of_day</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>247547</td>\n",
       "      <td>2015-06-28 03:00:34</td>\n",
       "      <td>2015-08-09 03:57:29</td>\n",
       "      <td>47</td>\n",
       "      <td>KIXYSVCHIPQBR</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Safari</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>16778864</td>\n",
       "      <td>0</td>\n",
       "      <td>16778240.0</td>\n",
       "      <td>16779263.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>3632215.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>220737</td>\n",
       "      <td>2015-01-28 14:21:11</td>\n",
       "      <td>2015-02-11 20:28:28</td>\n",
       "      <td>15</td>\n",
       "      <td>PKYOWQKWGJNJI</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>34</td>\n",
       "      <td>16842045</td>\n",
       "      <td>0</td>\n",
       "      <td>16809984.0</td>\n",
       "      <td>16842751.0</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>1231637.0</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>390400</td>\n",
       "      <td>2015-03-19 20:49:09</td>\n",
       "      <td>2015-04-11 23:41:23</td>\n",
       "      <td>44</td>\n",
       "      <td>LVCSXLISZHVUO</td>\n",
       "      <td>Ads</td>\n",
       "      <td>IE</td>\n",
       "      <td>M</td>\n",
       "      <td>29</td>\n",
       "      <td>16843656</td>\n",
       "      <td>0</td>\n",
       "      <td>16843264.0</td>\n",
       "      <td>16843775.0</td>\n",
       "      <td>China</td>\n",
       "      <td>1997534.0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>69592</td>\n",
       "      <td>2015-02-24 06:11:57</td>\n",
       "      <td>2015-05-23 16:40:14</td>\n",
       "      <td>55</td>\n",
       "      <td>UHAUHNXXUADJE</td>\n",
       "      <td>Direct</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>30</td>\n",
       "      <td>16938732</td>\n",
       "      <td>0</td>\n",
       "      <td>16924672.0</td>\n",
       "      <td>16941055.0</td>\n",
       "      <td>China</td>\n",
       "      <td>7640897.0</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174987</td>\n",
       "      <td>2015-07-07 12:58:11</td>\n",
       "      <td>2015-11-03 04:04:30</td>\n",
       "      <td>51</td>\n",
       "      <td>XPGPMOHIDRMGE</td>\n",
       "      <td>SEO</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>F</td>\n",
       "      <td>37</td>\n",
       "      <td>16971984</td>\n",
       "      <td>0</td>\n",
       "      <td>16941056.0</td>\n",
       "      <td>16973823.0</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>10249579.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id         signup_time       purchase_time  purchase_value  \\\n",
       "0   247547 2015-06-28 03:00:34 2015-08-09 03:57:29              47   \n",
       "1   220737 2015-01-28 14:21:11 2015-02-11 20:28:28              15   \n",
       "2   390400 2015-03-19 20:49:09 2015-04-11 23:41:23              44   \n",
       "3    69592 2015-02-24 06:11:57 2015-05-23 16:40:14              55   \n",
       "4   174987 2015-07-07 12:58:11 2015-11-03 04:04:30              51   \n",
       "\n",
       "       device_id  source browser sex  age  ip_address  class  \\\n",
       "0  KIXYSVCHIPQBR     SEO  Safari   F   30    16778864      0   \n",
       "1  PKYOWQKWGJNJI     SEO  Chrome   F   34    16842045      0   \n",
       "2  LVCSXLISZHVUO     Ads      IE   M   29    16843656      0   \n",
       "3  UHAUHNXXUADJE  Direct  Chrome   F   30    16938732      0   \n",
       "4  XPGPMOHIDRMGE     SEO  Chrome   F   37    16971984      0   \n",
       "\n",
       "   lower_bound_ip_address  upper_bound_ip_address    country  \\\n",
       "0              16778240.0              16779263.0  Australia   \n",
       "1              16809984.0              16842751.0   Thailand   \n",
       "2              16843264.0              16843775.0      China   \n",
       "3              16924672.0              16941055.0      China   \n",
       "4              16941056.0              16973823.0   Thailand   \n",
       "\n",
       "   time_to_purchase  hour_of_day  day_of_week  \n",
       "0         3632215.0            3            6  \n",
       "1         1231637.0           20            2  \n",
       "2         1997534.0           23            5  \n",
       "3         7640897.0           16            5  \n",
       "4        10249579.0            4            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_fraud_df1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop datetime columns from fraud data\n",
    "fraud_df_cleaned = merged_fraud_df1.drop(columns=['signup_time', 'purchase_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id                      int64\n",
       "purchase_value               int32\n",
       "device_id                 category\n",
       "source                    category\n",
       "browser                   category\n",
       "sex                       category\n",
       "age                          int32\n",
       "ip_address                   int32\n",
       "class                        int64\n",
       "lower_bound_ip_address     float64\n",
       "upper_bound_ip_address     float64\n",
       "country                     object\n",
       "time_to_purchase           float64\n",
       "hour_of_day                  int64\n",
       "day_of_week                  int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fraud_df_cleaned.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the data into train and test sets\n",
    "# For credit card data\n",
    "X_creditcard, y_creditcard = separate_features_target_creditcard(creditcard_df)\n",
    "X_creditcard_train, X_creditcard_test, y_creditcard_train, y_creditcard_test = split_train_test(X_creditcard, y_creditcard)\n",
    "\n",
    "# For fraud data (merged fraud data)\n",
    "X_fraud, y_fraud = separate_features_target_fraud(fraud_df_cleaned)\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = split_train_test(X_fraud, y_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit card train shape: (227845, 30), Credit card test shape: (56962, 30)\n",
      "Fraud data train shape: (103316, 14), Fraud data test shape: (25830, 14)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes to verify the splits\n",
    "print(f\"Credit card train shape: {X_creditcard_train.shape}, Credit card test shape: {X_creditcard_test.shape}\")\n",
    "print(f\"Fraud data train shape: {X_fraud_train.shape}, Fraud data test shape: {X_fraud_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns_fraud = ['age', 'ip_address', 'purchase_value', 'lower_bound_ip_address', 'upper_bound_ip_address', 'time_to_purchase', 'hour_of_day', 'day_of_week']\n",
    "categorical_columns_fraud = ['device_id', 'source', 'browser', 'sex', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_fraud = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns_fraud),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_columns_fraud)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "random_forest = RandomForestClassifier()\n",
    "gradient_boosting = GradientBoostingClassifier()\n",
    "mlp = MLPClassifier(max_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of models\n",
    "models = [logistic_regression, decision_tree, random_forest,gradient_boosting, mlp]\n",
    "\n",
    "# Preprocess the training and test data for fraud dataset\n",
    "X_fraud_train_transformed = preprocessor_fraud.fit_transform(X_fraud_train)\n",
    "X_fraud_test_transformed = preprocessor_fraud.transform(X_fraud_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
       "\twith 312654 stored elements and shape (25830, 95649)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_fraud_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/ftesfaye/Desktop/KIFIYA/KIFIYA_PROJECT_WEEK_8/Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions/notebooks/mlruns/845907924946011961', creation_time=1729753292179, experiment_id='845907924946011961', last_update_time=1729753292179, lifecycle_stage='active', name='Fraud Detection Models_v1', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Fraud Detection Models_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating LogisticRegression on fraud data...\n",
      "LogisticRegression Accuracy: 0.9524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     23427\n",
      "           1       0.96      0.51      0.67      2403\n",
      "\n",
      "    accuracy                           0.95     25830\n",
      "   macro avg       0.96      0.75      0.82     25830\n",
      "weighted avg       0.95      0.95      0.95     25830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 17:57:57 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating DecisionTreeClassifier on fraud data...\n",
      "DecisionTreeClassifier Accuracy: 0.9525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     23427\n",
      "           1       0.90      0.55      0.68      2403\n",
      "\n",
      "    accuracy                           0.95     25830\n",
      "   macro avg       0.93      0.77      0.83     25830\n",
      "weighted avg       0.95      0.95      0.95     25830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 18:04:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating RandomForestClassifier on fraud data...\n",
      "RandomForestClassifier Accuracy: 0.9567\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     23427\n",
      "           1       1.00      0.54      0.70      2403\n",
      "\n",
      "    accuracy                           0.96     25830\n",
      "   macro avg       0.98      0.77      0.84     25830\n",
      "weighted avg       0.96      0.96      0.95     25830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 18:12:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating GradientBoostingClassifier on fraud data...\n",
      "GradientBoostingClassifier Accuracy: 0.9568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98     23427\n",
      "           1       1.00      0.54      0.70      2403\n",
      "\n",
      "    accuracy                           0.96     25830\n",
      "   macro avg       0.98      0.77      0.84     25830\n",
      "weighted avg       0.96      0.96      0.95     25830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 18:13:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating MLPClassifier on fraud data...\n",
      "MLPClassifier Accuracy: 0.9499\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97     23427\n",
      "           1       0.86      0.55      0.67      2403\n",
      "\n",
      "    accuracy                           0.95     25830\n",
      "   macro avg       0.91      0.77      0.82     25830\n",
      "weighted avg       0.95      0.95      0.94     25830\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/24 21:16:24 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models for fraud data\n",
    "for model in models:\n",
    "    with mlflow.start_run(run_name=f\"{model.__class__.__name__}_fraud\"):\n",
    "        print(f\"Training and evaluating {model.__class__.__name__} on fraud data...\")\n",
    "        trained_model = train_and_evaluate_model(model, X_fraud_train_transformed, X_fraud_test_transformed, y_fraud_train, y_fraud_test)\n",
    "        \n",
    "        # Log model and performance metrics to MLflow\n",
    "        mlflow.sklearn.log_model(trained_model, f\"{model.__class__.__name__}_fraud_model\")\n",
    "        y_pred = trained_model.predict(X_fraud_test_transformed)\n",
    "        acc = accuracy_score(y_fraud_test, y_pred)\n",
    "        precision = precision_score(y_fraud_test, y_pred)\n",
    "        recall = recall_score(y_fraud_test, y_pred)\n",
    "        f1 = f1_score(y_fraud_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_params(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this based on the actual columns in the credit card dataset\n",
    "numerical_columns_creditcard = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15',\n",
    "                                'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_creditcard = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns_creditcard)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess and train for credit card data\n",
    "X_creditcard_train_transformed = preprocessor_creditcard.fit_transform(X_creditcard_train)\n",
    "X_creditcard_test_transformed = preprocessor_creditcard.transform(X_creditcard_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -8.43953559,   5.18252006, -12.31324996, ...,  -5.02350367,\n",
       "         -3.16294175,   1.0815138 ],\n",
       "       [  0.1730534 ,  -1.65602032,  -0.08791401, ...,   0.10210496,\n",
       "          0.30863538,   1.69317258],\n",
       "       [  0.71421679,  -0.35634288,   0.11194078, ...,   0.02847206,\n",
       "          0.013272  ,  -0.22547388],\n",
       "       ...,\n",
       "       [  0.02018331,  -0.06601034,  -0.83557264, ...,   0.89063984,\n",
       "          1.0738269 ,  -0.31714621],\n",
       "       [ -0.25325795,   0.59873588,   1.10429699, ...,   0.10094377,\n",
       "         -0.81883767,  -0.33299371],\n",
       "       [ -0.81263064,   0.59930001,  -0.33800407, ...,   0.31303049,\n",
       "         -1.8421089 ,   3.2080607 ]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_creditcard_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/ftesfaye/Desktop/KIFIYA/KIFIYA_PROJECT_WEEK_8/Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions/notebooks/mlruns/794011329361410109', creation_time=1729753314429, experiment_id='794011329361410109', last_update_time=1729753314429, lifecycle_stage='active', name='Credit Card Fraud Detection Models_v1', tags={}>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Credit Card Fraud Detection Models_v1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating LogisticRegression on credit card data...\n",
      "LogisticRegression Accuracy: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.86      0.57      0.69        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.93      0.79      0.84     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/25 11:39:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating DecisionTreeClassifier on credit card data...\n",
      "DecisionTreeClassifier Accuracy: 0.9991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.73      0.79      0.76        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.89      0.88     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/25 11:39:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating RandomForestClassifier on credit card data...\n",
      "RandomForestClassifier Accuracy: 0.9996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.96      0.78      0.86        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.98      0.89      0.93     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/25 11:43:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating GradientBoostingClassifier on credit card data...\n",
      "GradientBoostingClassifier Accuracy: 0.9989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.74      0.60      0.66        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.87      0.80      0.83     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/25 11:49:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating MLPClassifier on credit card data...\n",
      "MLPClassifier Accuracy: 0.9994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.81      0.83      0.82        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.90      0.91      0.91     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/25 11:50:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate models for credit card data\n",
    "for model in models:\n",
    "    with mlflow.start_run(run_name=f\"{model.__class__.__name__}_creditcard\"):\n",
    "        print(f\"Training and evaluating {model.__class__.__name__} on credit card data...\")\n",
    "        trained_model = train_and_evaluate_model(model, X_creditcard_train_transformed, X_creditcard_test_transformed, y_creditcard_train, y_creditcard_test)\n",
    "        \n",
    "        # Log model and performance metrics to MLflow\n",
    "        mlflow.sklearn.log_model(trained_model, f\"{model.__class__.__name__}_creditcard_model\")\n",
    "        y_pred = trained_model.predict(X_creditcard_test_transformed)\n",
    "        acc = accuracy_score(y_creditcard_test, y_pred)\n",
    "        precision = precision_score(y_creditcard_test, y_pred)\n",
    "        recall = recall_score(y_creditcard_test, y_pred)\n",
    "        f1 = f1_score(y_creditcard_test, y_pred)\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metric(\"accuracy\", acc)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "        mlflow.log_params(model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully for explainability tasks.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Load the   model from the specified path\n",
    "model_path = r'C:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\notebooks\\DecisionTreeClassifier().pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Now you can use this `model` for SHAP and LIME analysis\n",
    "print(\"Model loaded successfully for explainability tasks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split the data into train and test sets\n",
    "# For credit card data\n",
    "X_creditcard, y_creditcard = separate_features_target_creditcard(creditcard_df)\n",
    "X_creditcard_train, X_creditcard_test, y_creditcard_train, y_creditcard_test = split_train_test(X_creditcard, y_creditcard)\n",
    "\n",
    "# For fraud data (merged fraud data)\n",
    "X_fraud, y_fraud = separate_features_target_fraud(fraud_df_cleaned)\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = split_train_test(X_fraud, y_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the model\n",
    "model_path = r'C:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\notebooks\\DecisionTreeClassifier().pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Separate features and target for credit card data\n",
    "X_creditcard, y_creditcard = separate_features_target_creditcard(creditcard_df)\n",
    "X_creditcard_train, X_creditcard_test, y_creditcard_train, y_creditcard_test = split_train_test(X_creditcard, y_creditcard)\n",
    "\n",
    "# Initialize SHAP\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_creditcard_test)\n",
    "\n",
    "# SHAP Summary Plot\n",
    "shap.summary_plot(shap_values[1] if len(shap_values) > 1 else shap_values, X_creditcard_test)\n",
    "plt.show()\n",
    "\n",
    "# Force Plot (single prediction)\n",
    "if len(shap_values) > 1:\n",
    "    shap.force_plot(explainer.expected_value[1], shap_values[1][0, :], X_creditcard_test.iloc[0, :])\n",
    "else:\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0, :], X_creditcard_test.iloc[0, :])\n",
    "\n",
    "# Dependence Plot for a specific feature (e.g., 'age')\n",
    "shap.dependence_plot(\"purchase_value\", shap_values[1] if len(shap_values) > 1 else shap_values, X_creditcard_test)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\lime\\discretize.py:110: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  ret[feature] = int(self.lambdas[feature](ret[feature]))\n",
      "c:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\lime\\discretize.py:110: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  ret[feature] = int(self.lambdas[feature](ret[feature]))\n",
      "c:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\lime\\lime_tabular.py:544: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  binary_column = (inverse_column == first_row[column]).astype(int)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 14 features, but DecisionTreeClassifier is expecting 95649 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Pick an instance to explain (e.g., first instance in the test set)\u001b[39;00m\n\u001b[0;32m     28\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 29\u001b[0m exp \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplain_instance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_fraud_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpredict_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Display the explanation for this instance\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(exp\u001b[38;5;241m.\u001b[39mas_list())\n",
      "File \u001b[1;32mc:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\lime\\lime_tabular.py:355\u001b[0m, in \u001b[0;36mLimeTabularExplainer.explain_instance\u001b[1;34m(self, data_row, predict_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[0;32m    348\u001b[0m     scaled_data \u001b[38;5;241m=\u001b[39m (data \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mmean_) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale_\n\u001b[0;32m    349\u001b[0m distances \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mpairwise_distances(\n\u001b[0;32m    350\u001b[0m         scaled_data,\n\u001b[0;32m    351\u001b[0m         scaled_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m    352\u001b[0m         metric\u001b[38;5;241m=\u001b[39mdistance_metric\n\u001b[0;32m    353\u001b[0m )\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m--> 355\u001b[0m yss \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minverse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;66;03m# for classification, the model needs to provide a list of tuples - classes\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;66;03m# along with prediction probabilities\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:1042\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.predict_proba\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m   1018\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Predict class probabilities of the input samples X.\u001b[39;00m\n\u001b[0;32m   1019\u001b[0m \n\u001b[0;32m   1020\u001b[0m \u001b[38;5;124;03mThe predicted class probability is the fraction of samples of the same\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;124;03m    classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m-> 1042\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree_\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:489\u001b[0m, in \u001b[0;36mBaseDecisionTree._validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     force_all_finite \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    497\u001b[0m     X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc\n\u001b[0;32m    498\u001b[0m ):\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\sklearn\\base.py:654\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\venv\\Lib\\site-packages\\sklearn\\base.py:443\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 443\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 14 features, but DecisionTreeClassifier is expecting 95649 features as input."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import numpy as np\n",
    "\n",
    "# Load the saved model\n",
    "model_path = r'C:\\Users\\ftesfaye\\Desktop\\KIFIYA\\KIFIYA_PROJECT_WEEK_8\\Improved-Fraud-Detection-for-E-commerce-and-Bank-Transactions\\notebooks\\DecisionTreeClassifier().pkl'\n",
    "with open(model_path, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "# Separate features and target for fraud data\n",
    "X_fraud, y_fraud = separate_features_target_fraud(fraud_df_cleaned)\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = split_train_test(X_fraud, y_fraud)\n",
    "\n",
    "# Initialize LIME Explainer\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_fraud_train.values,\n",
    "    feature_names=X_fraud_train.columns,\n",
    "    class_names=['Non-Fraud', 'Fraud'],\n",
    "    mode='classification'\n",
    ")\n",
    "\n",
    "# Pick an instance to explain (e.g., first instance in the test set)\n",
    "i = 0\n",
    "exp = explainer.explain_instance(\n",
    "    data_row=X_fraud_test.iloc[i],\n",
    "    predict_fn=model.predict_proba\n",
    ")\n",
    "\n",
    "# Display the explanation for this instance\n",
    "exp.show_in_notebook()  # If using Jupyter, or use exp.as_list() for a list output\n",
    "print(exp.as_list())  # Prints the feature importance for the instance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
